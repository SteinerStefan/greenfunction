\section{Algorithmus}

	Da wir aus einer Matrix von Werten eine andere, gleich grosse  Matrix mit weiteren Werten berechnen, müssen wir zuerst diese Matrix in einen Vektor zerlegen.
	
	\begin{equation}
		\dunderline{A}\cdot \dunderline{X} \ne \dunderline{V} \qquad\Rightarrow\qquad \dunderline{A}\cdot \underline{x} = \underline{v}
		\label{eq:gleichung}
	\end{equation}
	
	Dabei haben wir bei beiden Matrizen die Spalten untereinander gereiht und so je einen Vektor mit der Länge $n^2$ erhalten. Mathematisch macht das keinen Unterschied, solange wir am Schluss den Lösungsvektor wieder auf die selbe Art und Weise zu einer Matrix zusammenfügen. Wir haben nun ein ganz normales lineares Gleichungssystem.
	
\[
	A=\left(
	\begin{array}{ccccc|ccccc|c|ccccc}
	    -4&     1&     0&\cdots&     0 &     1&     0&     0&\cdots&     0 &\cdots &      &      &      &      &      \\
	     1&    -4&     1&\cdots&     0 &     0&     1&     0&\cdots&     0 &\cdots &      &      &      &      &      \\
	     0&     1&    -4&\cdots&     0 &     0&     0&     1&\cdots&     0 &\cdots &      &      &     0&      &      \\
	\vdots&\vdots&\vdots&\ddots&\vdots &\vdots&\vdots&\vdots&\ddots&\vdots &       &      &      &      &      &      \\
	     0&     0&     0&\cdots&    -4 &     0&     0&     0&\dots &     1 &\cdots &      &      &      &      &      \\
	\hline
	     1&     0&     0&\cdots&     0 &    -4&     1&     0&\dots &     0 &\cdots &      &      &      &      &      \\
	     0&     1&     0&\cdots&     0 &     1&    -4&     1&\dots &     0 &\cdots &      &      &      &      &      \\
	     0&     0&     1&\cdots&     0 &     0&     1&    -4&\dots &     0 &\cdots &      &      &     0&      &      \\
	\vdots&\vdots&\vdots&\ddots&\vdots &\vdots&\vdots&\vdots&\ddots&\vdots &       &      &      &      &      &      \\
	     0&     0&     0&\cdots&     1 &     0&     0&     0&\cdots&    -4 &\cdots &      &      &      &      &      \\
	\hline
	\vdots&\vdots&\vdots&      &\vdots &\vdots&\vdots&\vdots&      &\vdots &\ddots &\vdots&\vdots&\vdots&      &\vdots\\
	\hline
	      &      &      &      &       &      &      &      &      &       &\cdots &    -4&     1&     0&\cdots&     0\\
	      &      &      &      &       &      &      &      &      &       &\cdots &     1&    -4&     1&\cdots&     0\\
	      &      &     0&      &       &      &      &     0&      &       &\cdots &     0&     1&    -4&\cdots&     0\\
	      &      &      &      &       &      &      &      &      &       &       &\vdots&\vdots&\vdots&\ddots&\vdots\\
	      &      &      &      &       &      &      &      &      &       &\cdots &     0&     0&     0&\cdots&    -4\\
	\end{array}
	\right) 
	\]
	
	Die Matrix $A$ enthält die Koeffizienten für die partielle Differentialgleichung 2. Ordnung, wie wir sie in der Vorlesung hergeleitet haben. Sie hat die Grösse $n^2 \times n^2$. Diese Matrix auf dem heap zu allozieren wäre für mittelgrosse Matrizen $V$ schon nicht mehr möglich.
	
	
	
	Der benötigte Speicher für eine Matrix $V$ mit der Grösse $500 \times 500$ und float Werten (4 Byte) wäre
	
	\begin{equation}
		500^2 \times 500^2 \cdot 4\;\mathrm{Byte} = 232.8\;\mathrm{GByte}
	\end{equation}
	
	Mit $n = 1000$ sogar 3.64\;TByte, also definitiv zuviel. Um dieses Problem zu umgehen, errechnen wir die Koeffizienten für jeden Schritt einzeln, was mit kleinem Zeitaufwand möglich ist da die Matrix $A$ dünn besetzt ist.
	
	Da die diskrete partielle Ableitung jeweils nur die Elemente ober/unterhalb und links/recht des aktuellen Elementes in die Rechnung mit einbezieht, müssen mindestens $n$ Iterationen durchgeführt werden, damit sich das Potential über die ganze Ebene verteilt.
	
	\subsection{Parallelisierung}
		
		Um das Gleichungssystem (\ref{eq:gleichung}) zu lösen, haben wir den Gauss-Seidel Algorithmus benutzt. Bei diesem Algorithmus ist, wie wir wissen, die aktuelle Zeile von der vorherigen abhängig. Bei der Parallelisierung wird das Gleichungssystem an verschiedenen Stellen zu lösen begonnen. Das ist zwar nicht so effizient, wie ein "'normaler"' Gauss-Seidel, wird aber durch die Parallelisierung schneller.
		
		Wir haben uns für OpenMP entschieden, da wir ein Grosses Problem haben, welches immer auf den selben Speicher zugreift. Wie schon beim Kugelsternhaufen erwähnt ist die Parallelisierung einfach zu realisieren:
		
\begin{code}
	int numthreads = 32;
	#pragma omp parallel for num_threads(numthreads)
		for (i = 0; i < dim; i++)
		{ ...
\end{code}