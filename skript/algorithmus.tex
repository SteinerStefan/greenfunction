\section{Algorithmus}

	Da wir aus einer Matrix von Werten eine andere, gleich grosse  Matrix mit weiteren Werten berechnen, müssen wir zuerst diese Matrix in einen Vektor zerlegen.
	
	\begin{equation}
		\dunderline{A}\cdot \dunderline{X} \ne \dunderline{V} \qquad\Rightarrow\qquad \dunderline{A}\cdot \underline{x} = \underline{v}
		\label{eq:gleichung}
	\end{equation}
	
	Dabei haben wir bei beiden Matrizen die Spalten untereinander gereiht und so je einen Vektor mit der Länge $n^2$ erhalten. Mathematisch macht das keinen Unterschied, solange wir am Schluss den Lösungsvektor wieder auf die selbe Art und Weise zu einer Matrix zusammenfügen. Wir haben nun ein ganz normales lineares Gleichungssystem.
	
\[
	A=\left(
	\begin{array}{ccccc|ccccc|c|ccccc}
	    -4&     1&     0&\cdots&     0 &     1&     0&     0&\cdots&     0 &\cdots &      &      &      &      &      \\
	     1&    -4&     1&\cdots&     0 &     0&     1&     0&\cdots&     0 &\cdots &      &      &      &      &      \\
	     0&     1&    -4&\cdots&     0 &     0&     0&     1&\cdots&     0 &\cdots &      &      &     0&      &      \\
	\vdots&\vdots&\vdots&\ddots&\vdots &\vdots&\vdots&\vdots&\ddots&\vdots &       &      &      &      &      &      \\
	     0&     0&     0&\cdots&    -4 &     0&     0&     0&\dots &     1 &\cdots &      &      &      &      &      \\
	\hline
	     1&     0&     0&\cdots&     0 &    -4&     1&     0&\dots &     0 &\cdots &      &      &      &      &      \\
	     0&     1&     0&\cdots&     0 &     1&    -4&     1&\dots &     0 &\cdots &      &      &      &      &      \\
	     0&     0&     1&\cdots&     0 &     0&     1&    -4&\dots &     0 &\cdots &      &      &     0&      &      \\
	\vdots&\vdots&\vdots&\ddots&\vdots &\vdots&\vdots&\vdots&\ddots&\vdots &       &      &      &      &      &      \\
	     0&     0&     0&\cdots&     1 &     0&     0&     0&\cdots&    -4 &\cdots &      &      &      &      &      \\
	\hline
	\vdots&\vdots&\vdots&      &\vdots &\vdots&\vdots&\vdots&      &\vdots &\ddots &\vdots&\vdots&\vdots&      &\vdots\\
	\hline
	      &      &      &      &       &      &      &      &      &       &\cdots &    -4&     1&     0&\cdots&     0\\
	      &      &      &      &       &      &      &      &      &       &\cdots &     1&    -4&     1&\cdots&     0\\
	      &      &     0&      &       &      &      &     0&      &       &\cdots &     0&     1&    -4&\cdots&     0\\
	      &      &      &      &       &      &      &      &      &       &       &\vdots&\vdots&\vdots&\ddots&\vdots\\
	      &      &      &      &       &      &      &      &      &       &\cdots &     0&     0&     0&\cdots&    -4\\
	\end{array}
	\right) 
	\]
	
	Die Matrix $A$ enthält die Koeffizienten für die partielle Differentialgleichung 2. Ordnung, wie wir sie in der Vorlesung hergeleitet haben. Sie hat die Grösse $n^2 \times n^2$. Diese Matrix auf dem heap zu allozieren wäre für mittelgrosse Matrizen $V$ schon nicht mehr möglich.
	
	
	
	Der benötigte Speicher für eine Matrix $V$ mit der Grösse $500 \times 500$ und float Werten (4 Byte) wäre
	
	\begin{equation}
		500^2 \times 500^2 \cdot 4\;\mathrm{Byte} = 232.8\;\mathrm{GByte}
	\end{equation}
	
	Mit $n = 1000$ sogar 3.64\;TByte, also definitiv zuviel. Um dieses Problem zu umgehen, errechnen wir die Koeffizienten für jeden Schritt einzeln, was mit kleinem Zeitaufwand möglich ist da die Matrix $A$ dünn besetzt ist.
	
	Da die diskrete partielle Ableitung jeweils nur die Elemente ober/unterhalb und links/recht des aktuellen Elementes in die Rechnung mit einbezieht, müssen mindestens $n$ Iterationen durchgeführt werden, damit sich das Potential über die ganze Ebene verteilt.
	
	\subsection{Parallelisierung}
		
		Um das Gleichungssystem (\ref{eq:gleichung}) zu lösen, haben wir den Gauss-Seidel Algorithmus benutzt. Bei diesem Algorithmus ist, wie wir wissen, die aktuelle Zeile von der vorherigen abhängig. Bei der Parallelisierung wird das Gleichungssystem an verschiedenen Stellen zu lösen begonnen. Das ist zwar nicht so effizient, wie ein "'normaler"' Gauss-Seidel, wird durch die Parallelisierung aber
		 schneller.
		
		Die Abweichung ist bei den ersten Schritten am grössten, und wird bei jeder Iteration kleiner. Als wie die ersten Berechnungen durch geführt hatten, fiel uns auf, dass die einzelnen Threads am Anfang gut als Linien von Spitzen sichtbar sind (\fref{fig:201_1}).
		
		\begin{figure}[h]
			\centering
			\includegraphics[width = 15cm]{./images/step001}
			\caption{Berechnung von einer $201 \times 201$ Fläche mit 32 Threads nach dem ersten Iterationsschritt}
			\label{fig:201_1}
		\end{figure}
		
		
		Wir haben uns für OpenMP entschieden, da wir ein Grosses Problem haben, welches immer auf den selben Speicher zugreift. Wie schon beim Kugelsternhaufen erwähnt, ist die Parallelisierung einfach zu realisieren:
		
\begin{code}
	int numthreads = 32;
	#pragma omp parallel for num_threads(numthreads)
		for (i = 0; i < dim; i++)
		{ ...
\end{code}

	\subsection{Probleme}
		
		Die Fläche $f$ kann alle möglichen Werte als Anfangsbedingung haben. Wir haben anfangs den  HSR-Schriftzug als FITS-File (Kapitel xxx) in eine Matrix 
% % % % % % % % % % TODO
		eingelesen. Der maximale Wert betrug anfangs nur 255,
		stieg nach einigen hundert Iterationen auf über 3000 an und die Funktion nahm die Form eines Haufen an. Wir hatten mit einem anderem Resultat gerechnet und überprüften unseren Algorithmus. Wir konnten keinen Fehler entdecken und konnten die Werte mit MATLAB verifizieren. Die nächste Frage war, ob der Gauss-Seidel konvergiert. Wir berechneten den Spektralradius der Matrix $A$ gemäss Definition\;5.1 aus dem Skript HPC:
		
		\begin{eqnarray}
			A = M+N\\
			\varrho(M^{-1}N)<1
		\end{eqnarray}
		
		Da die Berechnung schnell sehr rechenaufwendig wird, man beachte, dass die Grösse der Matrix $A$ mit $n^4$ zunimmt, haben wir Matrizen mit kleinen $n$ berechnet. 	
		
		\begin{table}[h]
			\begin{tabular}{cc}
				n & Specktralradius $\varrho$\\\midrule
				5 & 0.7500\\
				10 & 0.92063\\
				15 & 0.96194\\
				20 & 0.97779\\
				25 & 0.98547\\
				40 & 0.99414
			\end{tabular}
			\centering
			\caption{Spaktralradien der Matrix $A$ für eine Matrix $f$ mit der Grösse $n\times n$}
		\end{table}

		Einerseits sind alle Werte kleiner Eins, was gut ist, andererseits sind die Werte sehr nahe bei Eins, was erklärt wieso unser Algorithmus so langsam konvergiert.

% % % % % % % % % % TODO Grosse Werte erklären